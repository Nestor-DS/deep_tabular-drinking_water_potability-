{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nesto\\AppData\\Local\\Temp\\ipykernel_15856\\4047667229.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd                  # for tabular data manipulation and processing\n"
     ]
    }
   ],
   "source": [
    "# data management\n",
    "import numpy as np                   # for linear algebra\n",
    "import pandas as pd                  # for tabular data manipulation and processing\n",
    "\n",
    "           # for easy NN layer access\n",
    "\n",
    "# data visualization and graphics\n",
    "import matplotlib.pyplot as plt      # for visualization fundamentals\n",
    "import seaborn as sns                # for pretty visualizations\n",
    "import cv2                           # for image manipulation\n",
    "\n",
    "# misc\n",
    "from tqdm.notebook import tqdm       # for progress bars\n",
    "import math                          # for calculation\n",
    "import sys                           # for system manipulation\n",
    "import os  \n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "# Regression\n",
    "# \"Ground-truth values\"\n",
    "y_reg_true = np.random.uniform(0, 20, 50)        # Randomly generates number from uniform distribution with range 0 to 20 of size (50, 1)\n",
    "# Model predictions\n",
    "y_reg_pred = np.random.uniform(0, 20, 50)\n",
    "\n",
    "#Classification\n",
    "y_class_true = np.random.randint(2, size=50)        # Randomly generates 1s and 0s of size (50, 1)\n",
    "# Represents the probabilstic predictions from models\n",
    "y_class_pred = np.random.uniform(0, 1, 50)        # Randomly generates number from uniform distribution with range 0 to 1 of size (50, 1), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Implementation of MAE: 6.9427553460743745\n",
      "Sklearn Implementation of MAE: 6.9427553460743745\n"
     ]
    }
   ],
   "source": [
    "# Implementation in Numpy\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    # Check if y_true and y_pred are the same shape\n",
    "    assert y_pred.shape == y_true.shape\n",
    "    return np.sum(np.absolute(y_pred-y_true))/len(y_pred)\n",
    "\n",
    "print(f\"Numpy Implementation of MAE: {mean_absolute_error(y_reg_true, y_reg_pred)}\")\n",
    "\n",
    "# Implementation in Sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Usage\n",
    "print(f\"Sklearn Implementation of MAE: {mean_absolute_error(y_reg_true, y_reg_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Implementation of MSE: 74.82470930977259\n",
      "Sklearn Implementation of MSE: 74.82470930977259\n"
     ]
    }
   ],
   "source": [
    "# Implemnetation in Numpy\n",
    "def mean_squared_error(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
    "    assert y_pred.shape == y_true.shape\n",
    "    return np.sum((y_pred-y_true)**2)/len(y_pred)\n",
    "\n",
    "print(f\"Numpy Implementation of MSE: {mean_squared_error(y_reg_true, y_reg_pred)}\")\n",
    "\n",
    "# Implementation in Sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Usage\n",
    "print(f\"Sklearn Implementation of MSE: {mean_squared_error(y_reg_true, y_reg_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 8.650127704824513\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE: {mean_squared_error(y_reg_true, y_reg_pred) ** (1/2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under Reciver OPerating Characteristic Curve (AUC-ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tpr_fpr(y_pred, y_true):\n",
    "    tp = (y_pred == 1) & (y_true == 1)\n",
    "    tn = (y_pred == 0) & (y_true == 0)\n",
    "    fp = (y_pred == 1) & (y_true == 0)\n",
    "    fn = (y_pred == 0) & (y_true == 1)\n",
    "\n",
    "    tpr = tp.sum() / (tp.sum() + fn.sum())\n",
    "    fpr = fp.sum() / (fp.sum() + tn.sum())\n",
    "\n",
    "    return tpr, fpr\n",
    "\n",
    "def roc_curve(y_pred, y_true, n_thresholds=15000):\n",
    "    fpr_thresh = []\n",
    "    tpr_thresh = []\n",
    "    for i in range(n_thresholds + 1):\n",
    "        \n",
    "        threshold_vector = (y_pred >= i/n_thresholds)\n",
    "        tpr, fpr = get_tpr_fpr(threshold_vector, y_true)\n",
    "        fpr_thresh.append(fpr)\n",
    "        tpr_thresh.append(tpr)\n",
    "        \n",
    "    return tpr_thresh, fpr_thresh\n",
    "\n",
    "\n",
    "# Implementation in Numpy\n",
    "def area_under_roc_curve(y_true, y_pred):\n",
    "    fpr, tpr = roc_curve(y_pred, y_true)\n",
    "    rectangle_roc = 0\n",
    "    for k in range(len(fpr) - 1):\n",
    "            rectangle_roc = rectangle_roc + (fpr[k]- fpr[k + 1]) * tpr[k]\n",
    "    return 1 - rectangle_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Implementation of ROC-AUC: 0.5480769230769231\n",
      "Sklearn implementation of ROC-AUC: 0.5480769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(f\"Numpy Implementation of ROC-AUC: {area_under_roc_curve(y_class_true, y_class_pred)}\")\n",
    "print(f\"Sklearn implementation of ROC-AUC: {roc_auc_score(y_class_true, y_class_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! Recall and Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(y_true, y_pred):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mprecision(y_true, y_pred)\u001b[38;5;241m*\u001b[39mrecall(y_true, y_pred)) \u001b[38;5;241m/\u001b[39m (precision(y_true, y_pred)\u001b[38;5;241m+\u001b[39mrecall(y_true, y_pred))\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumpy Implementation of F1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_class_true\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43my_class_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSklearn Implementation of F1 Socre: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_score(y_class_true,\u001b[38;5;250m \u001b[39my_class_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(y_true, y_pred):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mprecision\u001b[49m(y_true, y_pred)\u001b[38;5;241m*\u001b[39mrecall(y_true, y_pred)) \u001b[38;5;241m/\u001b[39m (precision(y_true, y_pred)\u001b[38;5;241m+\u001b[39mrecall(y_true, y_pred))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'precision' is not defined"
     ]
    }
   ],
   "source": [
    "# F1 Score\n",
    "# Harmonic Mean of Precision and Recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    return (2*precision(y_true, y_pred)*recall(y_true, y_pred)) / (precision(y_true, y_pred)+recall(y_true, y_pred))\n",
    "\n",
    "print(f\"Numpy Implementation of F1 Score: {f1_score(y_class_true, y_class_pred)}\")\n",
    "    \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f\"Sklearn Implementation of F1 Socre: {f1_score(y_class_true, y_class_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
